# ML Project: Hotel Value Prediction

**Course Project for Kaggle Competition (Checkpoint 1)**

- **Authors:** Manav Jindal (IMT2023535), Arshbir Singh Dang (IMT2023132), Pushkar Kulkarni (IMT2023087)
- **Kaggle Team Name:** Dall-Eminators

---

## Project Overview

This project is a submission for the first checkpoint of our Machine Learning course's Kaggle competition. The objective is to predict the market value (`HotelValue`) of hotel properties based on a dataset of 79 features.

- **Target Variable:** `HotelValue`
- **Evaluation Metric:** Root Mean Squared Error (RMSE)
- **Model Constraints:** Only models from Part 1 of the course were permitted.

## Final Model & Approach

Our best-performing submission is generated by **`10_final_submission_model.py`**.

This model uses a **single, well-tuned linear model** (`Lasso` or `Ridge`) and is built on our most robust and stable preprocessing pipeline.

The success of this approach was built on a specific "simple and scaled" pipeline:
1.  **Log Transformation:** The target variable `HotelValue` was log-transformed (`np.log1p`).
2.  **Imputation:** Missing numerical values were filled with the `median`, and categorical values with the `mode`.
3.  **Simple Feature Engineering:** Only a few high-impact features were created (e.g., `TotalSF`, `PropertyAge`, `TotalBathrooms`).
4.  **Encoding:** All categorical features were one-hot encoded (`pd.get_dummies`).
5.  **Scaling:** The final feature set was scaled using `StandardScaler`, which proved critical for performance.

A key finding (detailed in our report) was that this simple, scaled linear approach significantly outperformed more complex tree-based ensembles (which overfit) and also outperformed more complex linear strategies that used aggressive feature engineering *without* scaling.

## How to Reproduce Our Best Submission

To generate our final, best-scoring submission file:

1.  **Prerequisites:**
    * Place the `train.csv` and `test.csv` files from Kaggle into the root of this repository.

2.  **Install Dependencies:**
    ```bash
    pip install pandas numpy scikit-learn
    ```

3.  **Run the Script:**
    ```bash
    python 10_final_submission_model.py
    ```

4.  **Output:**
    * This will run the complete "simple and scaled" pipeline, select the best model (`Lasso` or `Ridge`), and save the result as `submission.csv`.

## Repository Structure & Experimental Journey

This repository contains the full history of our experimental process. The scripts are numbered to tell the story of our project.

- **`Final_Project_Report.pdf`**
  * **This is our main submission document.** It details our full process, from EDA and hypothesis testing to our final conclusions.

### Hypothesis 1: Advanced Ensembles (Failed)

These scripts correspond to our experiments with complex models, which ultimately overfit and performed poorly on the leaderboard, as discussed in Section 5.2.1 of our report.

- **`01_initial_model_screening.py`**
  * **Start Here:** Our first script, used to test all 9 permitted model types.
- **`02_experiment_stacking_ensemble.py`**
  * An experiment with a complex, 5-model `StackingRegressor`.
- **`03_experiment_lightgbm_kfold.py`**
  * An experiment with `LightGBM` using K-Fold averaging.
- **`04_experiment_gbr_tuned.py`**
  * Our best-tuned `GradientBoostingRegressor` experiment.
- **`05_experiment_xgb_native_api.py`**
  * Our best-tuned `XGBoost` experiment using its native API.
- **`06_experiment_xgb_vs_ridge.py`**
  * A direct comparison of a tuned `XGBoost` (scikit-learn API) against our `Ridge` baseline.

### Hypothesis 2: Robust Linear Models (Winning Strategy)

This was a deep investigation into linear models with different preprocessing strategies.

- **`07_linear_model_tuning_baseline.py`**
  * **The "Simple + Scaled" Strategy:** Our first script for the winning pipeline. Uses simple features and `StandardScaler`.
- **`08_linear_model_aggressive_blend.py`**
  * **The "Aggressive + No-Scale" Strategy:** An experiment with aggressive feature engineering (polynomials, target encoding) and **no scaling**, using a 50/50 blend.
- **`09_linear_model_optimized_blend.py`**
  * **The "Optimal Blend" Strategy:** The most advanced experiment. Uses aggressive features, no scaling, and `scipy.optimize` to find the *optimal* blend weights for Lasso, Ridge, and ElasticNet.

### Final Winning Script

- **`10_final_submission_model.py`**
  * **WINNING SCRIPT:** This file represents the final, polished version of our best-performing "Simple + Scaled" strategy. It produced our top score on the Kaggle leaderboard.
